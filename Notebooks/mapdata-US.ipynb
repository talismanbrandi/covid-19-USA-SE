{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request as req\n",
    "import requests\n",
    "import ast\n",
    "\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "census_key = 'a4feafd1e894848eda9a783376cf7977222aecd2' ## The key from https://www.census.gov/data/developers.html \"Request a key\".\n",
    "\n",
    "# APIs from the US Census Bureau\n",
    "population_density_url = 'https://api.census.gov/data/2019/pep/population?get=DENSITY&in=state:*&for=county:*&key={}'.format(census_key)\n",
    "above_65_url = 'https://api.census.gov/data/2018/acs/acs5/subject?get=GEO_ID,NAME,S0101_C02_030E&in=state:*&for=county:*&key={}'.format(census_key)\n",
    "transport_url = 'https://api.census.gov/data/2018/acs/acs5?get=GEO_ID,NAME,B08006_001E,B08006_003E,B08006_017E&in=state:*&for=county:*&key={}'.format(census_key)\n",
    "race_url = 'https://api.census.gov/data/2018/acs/acs5/profile?get=GEO_ID,NAME,DP05_0070E,DP05_0077E&in=state:*&for=county:*&key={}'.format(census_key)\n",
    "poverty_url = 'https://api.census.gov/data/2018/acs/acs5/subject?get=GEO_ID,NAME,S1701_C03_001E&in=state:*&for=county:*&key={}'.format(census_key)\n",
    "income_url = 'https://api.census.gov/data/2018/acs/acs5/subject?get=GEO_ID,NAME,S1902_C03_019E&in=state:*&for=county:*&key={}'.format(census_key)\n",
    "employed_url = 'https://api.census.gov/data/2018/acs/acs5/subject?get=GEO_ID,NAME,S2301_C03_001E&in=state:*&for=county:*&key={}'.format(census_key)\n",
    "unemployment_url = 'https://api.census.gov/data/2018/acs/acs5/subject?get=GEO_ID,NAME,S2301_C04_001E&in=state:*&for=county:*&key={}'.format(census_key)\n",
    "mean_commute_url = 'https://api.census.gov/data/2018/acs/acs5/subject?get=GEO_ID,NAME,S0801_C01_046E&in=state:*&for=county:*&key={}'.format(census_key)\n",
    "labour_url = 'https://api.census.gov/data/2018/acs/acs5/profile?get=GEO_ID,NAME,DP03_0028PE,DP03_0030PE,DP03_0031PE&in=state:*&for=county:*&key={}'.format(census_key)\n",
    "insurance_url = 'https://api.census.gov/data/2018/acs/acs5/profile?get=GEO_ID,NAME,DP03_0099PE&in=state:*&for=county:*&key={}'.format(census_key)\n",
    "\n",
    "# links to the JHU GitHub\n",
    "jhu_deaths = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv'\n",
    "jhu_confirmed = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_census_data(url):\n",
    "    ''' A function to get the data from USA Census Bureau\n",
    "        arguments:\n",
    "            url: the url for the API call\n",
    "        return:\n",
    "            df: the dataframe with the pulled data\n",
    "    '''\n",
    "    df = pd.DataFrame(ast.literal_eval(req.urlopen(req.Request(url)).read().decode('utf8').replace('null', '\"1\"')))\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    df['FIPS'] = df.pop('GEO_ID').apply(lambda x: int(x[-5:]))\n",
    "    return df\n",
    "\n",
    "def exportjson(df, name):\n",
    "    ''' A function to export to json files\n",
    "        arguments:\n",
    "            df: the dataframe to export\n",
    "            name: the name of the file without the '.json'\n",
    "    '''\n",
    "    df_json = df[['code', 'name', name]]\n",
    "    df_json.rename(columns={name: 'value'}, inplace=True)\n",
    "    with open('../Maps/data/US/'+name+'.json', 'w') as file:\n",
    "        file.write(df_json.to_json(orient='records'))\n",
    "    print('10 percentile ('+name+'): {}'.format(df[df['Density'] > 0][name].quantile(0.10)))\n",
    "    print('90 percentile ('+name+'): {}'.format(df[df['Density'] > 0][name].quantile(0.90)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "## The density data from census.gov\n",
    "density = pd.DataFrame(ast.literal_eval(req.urlopen(req.Request(population_density_url)).read().decode('utf8').replace('null', '\"0\"')))\n",
    "density.columns = density.iloc[0]\n",
    "density = density[1:]\n",
    "density.DENSITY = density.DENSITY.astype('float32')\n",
    "density.state = density.state.astype('string')\n",
    "density.county = density.county.astype('string')\n",
    "density['FIPS'] = density['state'] + density['county']\n",
    "density.FIPS = density.FIPS.astype('int32')\n",
    "density = density.drop(labels=['state', 'county'], axis=1)\n",
    "columns = density.columns.tolist()\n",
    "columns = columns[::-1]\n",
    "density = density[columns]\n",
    "density.rename(columns={'DENSITY': 'Density'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The FIPS and state names\n",
    "df_census = get_census_data(above_65_url)\n",
    "df_census = df_census[['FIPS', 'NAME']]\n",
    "df_census['County'] = df_census['NAME'].str.split(', ').str[0]\n",
    "df_census['State'] = df_census.pop('NAME').str.split(', ').str[1]\n",
    "df_census = df_census.sort_values(df_census.columns[0], ignore_index=True)\n",
    "df_census = pd.merge(df_census, density, on='FIPS')\n",
    "\n",
    "# 2018 5 year ACS data on Age\n",
    "dft = get_census_data(above_65_url)\n",
    "dft = dft[['FIPS', 'S0101_C02_030E']]\n",
    "dft.rename(columns={'S0101_C02_030E': 'Senior Citizen'}, inplace=True)\n",
    "df_census = pd.merge(df_census, dft, on='FIPS')\n",
    "df_census['Senior Citizen'] = df_census['Senior Citizen'].apply(lambda x: float(x))/100.\n",
    "\n",
    "# 2018 5 year ACS data on transport used\n",
    "dft = get_census_data(transport_url)\n",
    "dft['Transit-1'] = 1. - (dft['B08006_003E'].astype('float')+dft['B08006_017E'].astype('float'))/dft['B08006_001E'].astype('float')\n",
    "dft = dft[['FIPS', 'Transit-1']]\n",
    "df_census = pd.merge(df_census, dft, on='FIPS')\n",
    "df_census['Transit'] = df_census.pop('Transit-1')\n",
    "df_census.at[df_census[df_census['FIPS']==35039].index, 'Transit'] = 0.159 ## Imputed value from 2011 since values are null in 2018\n",
    "\n",
    "# 2018 5 year ACS data on non-white\n",
    "dft = get_census_data(race_url)\n",
    "dft['Non-White'] = 1. - dft['DP05_0077E'].astype('float')/dft['DP05_0070E'].astype('float')\n",
    "dft = dft[['FIPS', 'Non-White']]\n",
    "df_census = pd.merge(df_census, dft, on='FIPS')\n",
    "\n",
    "# 2018 5 year ACS data on Poverty\n",
    "dft = get_census_data(poverty_url)\n",
    "dft = dft[['FIPS', 'S1701_C03_001E']]\n",
    "dft.rename(columns={'S1701_C03_001E': 'Poverty-1'}, inplace=True)\n",
    "df_census = pd.merge(df_census, dft, on='FIPS')\n",
    "df_census['Poverty'] = df_census.pop('Poverty-1').apply(lambda x: float(x))/100.\n",
    "df_census.at[df_census[df_census['FIPS']==35039].index, 'Poverty'] = 0.237 ## Imputed value from 2011 since values are null in 2018\n",
    "\n",
    "# 2018 5 year ACS data on Income per capita\n",
    "dft = get_census_data(income_url)\n",
    "dft = dft[['FIPS', 'S1902_C03_019E']]\n",
    "dft.rename(columns={'S1902_C03_019E': 'Income/Capita'}, inplace=True)\n",
    "df_census = pd.merge(df_census, dft, on='FIPS')\n",
    "df_census['Income/Capita'] = df_census['Income/Capita'].apply(lambda x: float(x))\n",
    "df_census.at[df_census[df_census['FIPS']==35039].index, 'Income/Capita'] = 19678 ## Imputed value from 2011 since values are null in 2018\n",
    "\n",
    "# 2018 5 year ACS data on Employment\n",
    "dft = get_census_data(employed_url)\n",
    "dft = dft[['FIPS', 'S2301_C03_001E']]\n",
    "dft.rename(columns={'S2301_C03_001E': 'Employed-1'}, inplace=True)\n",
    "df_census = pd.merge(df_census, dft, on='FIPS')\n",
    "df_census['Employed'] = df_census.pop('Employed-1').apply(lambda x: float(x))/100.\n",
    "df_census.at[df_census[df_census['FIPS']==35039].index, 'Employed'] = 0.382287 ## Imputed value from 2011 since values are null in 2018\n",
    "\n",
    "# 2018 5 year ACS data on Unemployment\n",
    "dft = get_census_data(unemployment_url)\n",
    "dft = dft[['FIPS', 'S2301_C04_001E']]\n",
    "dft.rename(columns={'S2301_C04_001E': 'Unemployment-1'}, inplace=True)\n",
    "df_census = pd.merge(df_census, dft, on='FIPS')\n",
    "df_census['Unemployment'] = df_census.pop('Unemployment-1').apply(lambda x: float(x))/100.\n",
    "df_census.at[df_census[df_census['FIPS']==35039].index, 'Unemployment'] = 0.114 ## Imputed value from 2011 since values are null in 2018\n",
    "\n",
    "# 2018 5 year ACS data on Mean Commute in minutes\n",
    "dft = get_census_data(mean_commute_url)\n",
    "dft = dft[['FIPS', 'S0801_C01_046E']]\n",
    "dft.rename(columns={'S0801_C01_046E': 'MeanCommute'}, inplace=True)\n",
    "df_census = pd.merge(df_census, dft, on='FIPS')\n",
    "df_census['MeanCommute'] = df_census['MeanCommute'].apply(lambda x: float(x))\n",
    "df_census.at[df_census[df_census['FIPS']==35039].index, 'MeanCommute'] = 26.2 ## Imputed value from 2011 since values are null in 2018\n",
    "df_census.at[df_census[df_census['FIPS']==48301].index, 'MeanCommute'] = 25.4 ## Imputed value from 2011 since values are null in 2018\n",
    "\n",
    "# 2018 5 year ACS data on Labour\n",
    "dft = get_census_data(labour_url)\n",
    "dft['Labour'] = (dft['DP03_0028PE'].astype('float') + dft['DP03_0030PE'].astype('float') + dft['DP03_0031PE'].astype('float'))/100.\n",
    "dft = dft[['FIPS', 'Labour']]\n",
    "df_census = pd.merge(df_census, dft, on='FIPS')\n",
    "df_census.at[df_census[df_census['FIPS']==35039].index, 'Labour'] = 0.271 + 0.108 + 0.07 ## Imputed value from 2011 since values are null in 2018\n",
    "\n",
    "# 2018 5 year ACS data on Health Insurance\n",
    "dft = get_census_data(insurance_url)\n",
    "dft = dft[['FIPS', 'DP03_0099PE']]\n",
    "dft.rename(columns={'DP03_0099PE': 'Uninsured'}, inplace=True)\n",
    "df_census = pd.merge(df_census, dft, on='FIPS')\n",
    "df_census['Uninsured'] = df_census.pop('Uninsured').apply(lambda x: float(x))/100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 percentile (Non-White): 4.570574181924518\n",
      "90 percentile (Non-White): 54.597917169690504\n",
      "\n",
      "10 percentile (Income): 20168.800000000003\n",
      "90 percentile (Income): 34470.700000000004\n",
      "\n",
      "10 percentile (Poverty): 8.4\n",
      "90 percentile (Poverty): 24.0\n",
      "\n",
      "10 percentile (Unemployment): 2.7\n",
      "90 percentile (Unemployment): 9.0\n",
      "\n",
      "10 percentile (Uninsured): 4.7\n",
      "90 percentile (Uninsured): 16.8\n",
      "\n",
      "10 percentile (Employed): 44.1\n",
      "90 percentile (Employed): 65.1\n",
      "\n",
      "10 percentile (Labour): 38.099999999999994\n",
      "90 percentile (Labour): 56.190000000000005\n",
      "\n",
      "10 percentile (Transit): 10.275783364747099\n",
      "90 percentile (Transit): 20.761741402036087\n",
      "\n",
      "10 percentile (MeanCommute): 16.5\n",
      "90 percentile (MeanCommute): 31.0\n",
      "\n",
      "10 percentile (Senior Citizen): 12.9\n",
      "90 percentile (Senior Citizen): 24.3\n",
      "\n",
      "10 percentile (Density): 4.0626819133758545\n",
      "90 percentile (Density): 408.30596008300785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate the data files in the correct format\n",
    "data_map = df_census.copy(deep=True)\n",
    "data_map['FIPS'] = data_map['FIPS'].apply(str).apply(lambda x: '{0:0>5}'.format(x)).apply(lambda x : x[2:])\n",
    "data_map['State'] = data_map['State'].apply(lambda x: us_state_abbrev[x].lower())\n",
    "data_map['code'] = 'us-'+data_map['State']+'-'+data_map['FIPS']\n",
    "data_map['name'] = data_map['County']+', '+data_map['State'].apply(lambda x: x.upper())\n",
    "\n",
    "# Non-White\n",
    "data_map['Non-White'] = data_map['Non-White']*100.\n",
    "exportjson(data_map, 'Non-White')\n",
    "\n",
    "# Income\n",
    "data_map['Income'] = data_map['Income/Capita']\n",
    "exportjson(data_map, 'Income')\n",
    "\n",
    "# Poverty\n",
    "data_map['Poverty'] = data_map['Poverty']*100.\n",
    "exportjson(data_map, 'Poverty')\n",
    "\n",
    "# Unemployment\n",
    "data_map['Unemployment'] = data_map['Unemployment']*100.\n",
    "exportjson(data_map, 'Unemployment')\n",
    "\n",
    "# Uninsured\n",
    "data_map['Uninsured'] = data_map['Uninsured']*100.\n",
    "exportjson(data_map, 'Uninsured')\n",
    "\n",
    "# Employed\n",
    "data_map['Employed'] = data_map['Employed']*100.\n",
    "exportjson(data_map, 'Employed')\n",
    "\n",
    "# Labour\n",
    "data_map['Labour'] = data_map['Labour']*100.\n",
    "exportjson(data_map, 'Labour')\n",
    "\n",
    "# Transit\n",
    "data_map['Transit'] = data_map['Transit']*100.\n",
    "exportjson(data_map, 'Transit')\n",
    "\n",
    "# Mean Commute\n",
    "exportjson(data_map, 'MeanCommute')\n",
    "\n",
    "# Senior Citizen\n",
    "data_map['Senior Citizen'] = data_map['Senior Citizen']*100.\n",
    "exportjson(data_map, 'Senior Citizen')\n",
    "\n",
    "exportjson(data_map, 'Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 percentile (death rate): 0.0\n",
      "90 percentile (death rate): 75.90000000000009\n"
     ]
    }
   ],
   "source": [
    "# The data file for the death rates\n",
    "deaths = pd.read_csv(jhu_deaths)\n",
    "deaths.drop(deaths[(deaths['FIPS'] < 1000) | (deaths['FIPS'] > 57000)].index , inplace=True)\n",
    "deaths.dropna(inplace=True)\n",
    "\n",
    "data_deaths = deaths.copy(deep=True)\n",
    "data_deaths['FIPS'] = data_deaths['FIPS'].apply(int).apply(str).apply(lambda x: '{0:0>5}'.format(x)).apply(lambda x : x[2:])\n",
    "data_deaths['Province_State'] = data_deaths['Province_State'].apply(lambda x: us_state_abbrev[x].lower())\n",
    "data_deaths['value'] = round((data_deaths['8/16/20']/data_deaths['Population']*100000).apply(int))\n",
    "data_deaths['code'] = 'us-'+data_deaths['Province_State']+'-'+data_deaths['FIPS']\n",
    "data_deaths['name'] = data_deaths['Admin2']+' County, '+data_deaths['Province_State'].apply(lambda x: x.upper())\n",
    "data_deaths = data_deaths[['code', 'name', 'value']]\n",
    "with open('../Maps/data/US/deaths.json', 'w') as file:\n",
    "    file.write(data_deaths.to_json(orient='records'))\n",
    "    \n",
    "print('10 percentile (death rate): {}'.format(data_deaths['value'].quantile(0.10)))\n",
    "print('90 percentile (death rate): {}'.format(data_deaths['value'].quantile(0.90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 percentile (confirmed rate): 228.0\n",
      "90 percentile (confirmed rate): 2628.800000000001\n"
     ]
    }
   ],
   "source": [
    "# The data file for the confirmed case rate\n",
    "confirmed = pd.read_csv(jhu_confirmed)\n",
    "confirmed.drop(confirmed[(confirmed['FIPS'] < 1000) | (confirmed['FIPS'] > 57000)].index , inplace=True)\n",
    "confirmed.dropna(inplace=True)\n",
    "confirmed['Population'] = deaths['Population']\n",
    "\n",
    "data_confirmed = confirmed.copy(deep=True)\n",
    "data_confirmed['FIPS'] = data_confirmed['FIPS'].apply(int).apply(str).apply(lambda x: '{0:0>5}'.format(x)).apply(lambda x : x[2:])\n",
    "data_confirmed['Province_State'] = data_confirmed['Province_State'].apply(lambda x: us_state_abbrev[x].lower())\n",
    "data_confirmed['value'] = round((data_confirmed['8/16/20']/data_confirmed['Population']*100000).apply(int))\n",
    "data_confirmed['code'] = 'us-'+data_confirmed['Province_State']+'-'+data_confirmed['FIPS']\n",
    "data_confirmed['name'] = data_confirmed['Admin2']+' County, '+data_confirmed['Province_State'].apply(lambda x: x.upper())\n",
    "data_confirmed = data_confirmed[['code', 'name', 'value']]\n",
    "with open('../Maps/data/US/confirmed.json', 'w') as file:\n",
    "    file.write(data_confirmed.to_json(orient='records'))\n",
    "    \n",
    "print('10 percentile (confirmed rate): {}'.format(data_confirmed['value'].quantile(0.10)))\n",
    "print('90 percentile (confirmed rate): {}'.format(data_confirmed['value'].quantile(0.90)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Tutorials)",
   "language": "python",
   "name": "pycharm-38c7cf03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
